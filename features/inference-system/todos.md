# Inference System - Implementation Tasks

**Feature**: ì¶”ë¡  ì‹œìŠ¤í…œ (Inference System)
**Status**: ğŸš§ In Development
**Target Version**: 3.2.0

---

## Phase 1: Core Inference Implementation

### Task 1.1: InferenceEngine ìºì‹œ ìµœì í™”
**Status**: â³ Pending
**Priority**: High
**Files**: `src/database/inference/InferenceEngine.ts`

**Tasks**:
- [ ] ìºì‹œ í‚¤ ì„¤ê³„ (query type + parameters)
- [ ] LRU ìºì‹œ êµ¬í˜„ (max 1000 entries)
- [ ] ìºì‹œ ë¬´íš¨í™” ì „ëµ (DB ë³€ê²½ ì‹œ)
- [ ] ìºì‹œ hit/miss ë©”íŠ¸ë¦­

**Implementation**:
```typescript
// InferenceEngine.ts
class InferenceEngine {
  private cache: LRUCache<string, InferenceResult>;

  constructor(db: GraphDatabase, options: InferenceEngineConfig) {
    this.cache = new LRUCache({
      max: options.cacheSize || 1000,
      ttl: options.cacheTTL || 60000  // 1ë¶„
    });
  }

  async queryHierarchical(
    edgeType: string,
    options: HierarchicalQueryOptions
  ): Promise<InferredRelationship[]> {
    const cacheKey = `hierarchical:${edgeType}:${JSON.stringify(options)}`;

    // ìºì‹œ í™•ì¸
    if (this.cache.has(cacheKey)) {
      return this.cache.get(cacheKey)!;
    }

    // ì¿¼ë¦¬ ì‹¤í–‰
    const result = await this._executeHierarchicalQuery(edgeType, options);

    // ìºì‹œ ì €ì¥
    this.cache.set(cacheKey, result);

    return result;
  }

  invalidateCache(): void {
    this.cache.clear();
  }
}
```

**Acceptance Criteria**:
- ìºì‹œ hit rate > 70%
- ì„±ëŠ¥ í–¥ìƒ > 3ë°°
- Memory usage < 100MB

**Known Challenges**:
- ìºì‹œ ë¬´íš¨í™” ì‹œì  ì •í™•íˆ ê²°ì •
- Cache key ì¶©ëŒ ë°©ì§€

---

### Task 1.2: Incremental Inference
**Status**: â³ Pending
**Priority**: High
**Files**: `src/database/inference/InferenceEngine.ts`

**Tasks**:
- [ ] ë³€ê²½ëœ ë…¸ë“œ ì¶”ì  (dirty flag)
- [ ] ì˜í–¥ë°›ëŠ” inferenceë§Œ ì¬ì‹¤í–‰
- [ ] Incremental update ì•Œê³ ë¦¬ì¦˜

**Implementation**:
```typescript
// InferenceEngine.ts
class InferenceEngine {
  private dirtyNodes: Set<number> = new Set();

  markDirty(nodeId: number): void {
    this.dirtyNodes.add(nodeId);
  }

  async inferIncremental(): Promise<InferenceResult> {
    const results: InferenceResult = {
      updated: [],
      removed: [],
      added: []
    };

    for (const nodeId of this.dirtyNodes) {
      // 1. ê¸°ì¡´ ì¶”ë¡ ëœ edge ì œê±°
      const oldInferred = await this.db.findEdges({
        fromNodeId: nodeId,
        metadata: { isInferred: true }
      });

      for (const edge of oldInferred) {
        await this.db.deleteEdge(edge.id);
        results.removed.push(edge);
      }

      // 2. ìƒˆë¡œìš´ ì¶”ë¡  ì‹¤í–‰
      const newInferred = await this.inferAll(nodeId);
      results.added.push(...newInferred);
    }

    this.dirtyNodes.clear();
    return results;
  }
}

// GraphDatabase.ts
class GraphDatabase {
  async upsertNode(node: GraphNode): Promise<GraphNode> {
    const result = await this._upsertNode(node);

    // InferenceEngineì— ë³€ê²½ ì•Œë¦¼
    this.inferenceEngine?.markDirty(result.id);

    return result;
  }
}
```

**Acceptance Criteria**:
- ë³€ê²½ëœ ë…¸ë“œë§Œ ì¬ì¶”ë¡ 
- ì„±ëŠ¥ í–¥ìƒ > 10ë°° (ëŒ€ê·œëª¨ í”„ë¡œì íŠ¸)
- ì¶”ë¡  ê²°ê³¼ ì •í™•ë„ 100%

---

### Task 1.3: Symbol-Level Inference
**Status**: â³ Pending
**Priority**: Medium
**Files**: `src/database/inference/SymbolInferenceEngine.ts`

**Tasks**:
- [ ] SymbolInferenceEngine í´ë˜ìŠ¤ ìƒì„±
- [ ] Method call chain ì¶”ë¡ 
- [ ] Type propagation ì¶”ë¡ 
- [ ] Symbol-level transitive query

**Implementation**:
```typescript
// SymbolInferenceEngine.ts
class SymbolInferenceEngine extends InferenceEngine {
  async inferMethodCalls(options: {
    file: string;
    method: string;
  }): Promise<MethodCallChain[]> {
    // 1. ë©”ì„œë“œ ë…¸ë“œ ì°¾ê¸°
    const methodNode = await this.db.findNode({
      sourceFile: options.file,
      name: options.method
    });

    // 2. í˜¸ì¶œ ì²´ì¸ ì¶”ë¡ 
    const callChain = await this.queryTransitive(methodNode.id, 'calls', {
      maxPathLength: 5,
      direction: 'outgoing'
    });

    return callChain.map(rel => ({
      path: rel.path,
      depth: rel.pathLength,
      methods: rel.path.map(nodeId => this.db.getNode(nodeId))
    }));
  }

  async inferTypePropagation(variableNode: GraphNode): Promise<GraphNode> {
    // Variableì˜ íƒ€ì… ì¶”ë¡ 
    // 1. Assignment ì¶”ì 
    // 2. Type annotation í™•ì¸
    // 3. ìµœì¢… íƒ€ì… ë°˜í™˜
  }
}
```

**Acceptance Criteria**:
- Method call chain ì •í™•íˆ ì¶”ì 
- Type propagation ì •í™•ë„ > 85%
- Symbol-level query ì§€ì›

---

## Phase 2: Advanced Query Language

### Task 2.1: Cypher-like Query Parser
**Status**: â³ Pending
**Priority**: Low
**Files**: `src/database/query/CypherParser.ts`

**Tasks**:
- [ ] Cypher ë¬¸ë²• íŒŒì„œ êµ¬í˜„
- [ ] AST ìƒì„±
- [ ] SQL ë³€í™˜

**Query Examples**:
```cypher
// 1. ê°„ë‹¨í•œ ì˜ì¡´ì„± ì¡°íšŒ
MATCH (file:File)-[dep:DEPENDS_ON]->(target:File)
WHERE file.namespace = 'tests'
RETURN file, dep, target

// 2. ì „ì´ì  ì˜ì¡´ì„±
MATCH (file:File)-[dep:DEPENDS_ON*1..3]->(target:File)
WHERE file.name = 'App.tsx'
RETURN file, dep, target

// 3. ì˜í–¥ ë¶„ì„
MATCH (file:File)<-[dep:DEPENDS_ON*]-(dependent:File)
WHERE file.name = 'QueryEngine.ts'
RETURN dependent, COUNT(dep) as impact_score
ORDER BY impact_score DESC
```

**Implementation**:
```typescript
// CypherParser.ts
class CypherParser {
  parse(query: string): QueryAST {
    // Cypher query â†’ AST
  }

  toSQL(ast: QueryAST): string {
    // AST â†’ SQL (Recursive CTE)
  }
}

// CypherExecutor.ts
class CypherExecutor {
  async execute(query: string): Promise<QueryResult> {
    const ast = this.parser.parse(query);
    const sql = this.parser.toSQL(ast);
    return await this.db.raw(sql);
  }
}

// ì‚¬ìš©
const executor = new CypherExecutor(db);
const result = await executor.execute(`
  MATCH (file:File)-[dep:DEPENDS_ON*1..3]->(target:File)
  WHERE file.name = 'App.tsx'
  RETURN file, dep, target
`);
```

**Acceptance Criteria**:
- Cypher ê¸°ë³¸ ë¬¸ë²• ì§€ì› (MATCH, WHERE, RETURN)
- ì „ì´ì  ì¿¼ë¦¬ ì§€ì› (`*1..3`)
- SQL ë³€í™˜ ì •í™•ë„ 100%

**Known Challenges**:
- Cypher ë¬¸ë²• ë³µì¡ë„
- SQL Recursive CTE í•œê³„

---

## Phase 3: Custom Inference Rules

### Task 3.1: InferenceRule Registry
**Status**: â³ Pending
**Priority**: Medium
**Files**: `src/database/inference/InferenceRuleRegistry.ts`

**Tasks**:
- [ ] InferenceRule íƒ€ì… ì •ì˜
- [ ] Registry êµ¬í˜„
- [ ] Rule execution engine

**Implementation**:
```typescript
// InferenceRuleRegistry.ts
interface InferenceRule {
  name: string;
  description: string;
  match: (edge: GraphEdge) => boolean;
  infer: (edge: GraphEdge) => Promise<InferredEdge[]>;
  priority: number;
}

class InferenceRuleRegistry {
  private rules: Map<string, InferenceRule> = new Map();

  registerRule(rule: InferenceRule): void {
    this.rules.set(rule.name, rule);
  }

  async executeRules(edge: GraphEdge): Promise<InferredEdge[]> {
    const results: InferredEdge[] = [];

    // Priority ìˆœì„œë¡œ ì‹¤í–‰
    const sortedRules = Array.from(this.rules.values())
      .sort((a, b) => b.priority - a.priority);

    for (const rule of sortedRules) {
      if (rule.match(edge)) {
        const inferred = await rule.infer(edge);
        results.push(...inferred);
      }
    }

    return results;
  }
}
```

**Acceptance Criteria**:
- Custom rule ë“±ë¡ ê°€ëŠ¥
- Priority ê¸°ë°˜ ì‹¤í–‰
- Rule conflict í•´ê²°

---

### Task 3.2: Built-in Inference Rules
**Status**: â³ Pending
**Priority**: Medium
**Files**: `src/database/inference/rules/*.ts`

**Tasks**:
- [ ] Controller-Service pattern rule
- [ ] Repository-Entity pattern rule
- [ ] Test-Source mapping rule

**Example Rules**:
```typescript
// rules/controller-service.ts
export const controllerServiceRule: InferenceRule = {
  name: 'controller-service-pattern',
  description: 'Infer service dependency from controller',
  priority: 10,

  match: (edge) => {
    return edge.source.endsWith('Controller.ts') &&
           edge.type === 'imports';
  },

  infer: async (edge) => {
    const serviceName = edge.source.replace('Controller', 'Service');

    // Service íŒŒì¼ ì¡´ì¬ í™•ì¸
    const serviceNode = await db.findNode({
      sourceFile: serviceName
    });

    if (!serviceNode) return [];

    // Controller â†’ Service ì¶”ë¡  edge
    return [{
      fromNodeId: edge.fromNodeId,
      toNodeId: serviceNode.id,
      type: 'requires-service',
      metadata: {
        isInferred: true,
        inferenceRule: 'controller-service-pattern',
        confidence: 0.8
      }
    }];
  }
};

// ë“±ë¡
registry.registerRule(controllerServiceRule);
```

**Acceptance Criteria**:
- 3ê°œ ì´ìƒì˜ built-in rules
- Confidence score ì œê³µ
- ë¬¸ì„œí™” ì™„ë£Œ

---

## Phase 4: Real-Time Inference

### Task 4.1: File Watcher Integration
**Status**: â³ Pending
**Priority**: Low
**Files**: `src/watch/InferenceWatcher.ts`

**Tasks**:
- [ ] File watcher ì„¤ì •
- [ ] ë³€ê²½ ê°ì§€ â†’ ì¦ë¶„ ì¶”ë¡ 
- [ ] Debouncing ì²˜ë¦¬

**Implementation**:
```typescript
// InferenceWatcher.ts
import chokidar from 'chokidar';

class InferenceWatcher {
  private watcher: chokidar.FSWatcher;
  private debounceTimer: NodeJS.Timeout | null = null;

  async start(options: WatchOptions): Promise<void> {
    this.watcher = chokidar.watch(options.patterns, {
      ignored: options.ignored,
      persistent: true
    });

    this.watcher.on('change', (path) => {
      this.scheduleInference(path);
    });
  }

  private scheduleInference(path: string): void {
    if (this.debounceTimer) {
      clearTimeout(this.debounceTimer);
    }

    this.debounceTimer = setTimeout(async () => {
      await this.inferForFile(path);
    }, 500);  // 500ms debounce
  }

  private async inferForFile(path: string): Promise<void> {
    // 1. íŒŒì¼ ì¬ë¶„ì„
    await analyzer.analyzeFile(path);

    // 2. ì˜í–¥ë°›ëŠ” ë…¸ë“œë§Œ ì¶”ë¡ 
    const nodes = await db.findNodes({ sourceFiles: [path] });
    for (const node of nodes) {
      engine.markDirty(node.id);
    }

    // 3. ì¦ë¶„ ì¶”ë¡  ì‹¤í–‰
    await engine.inferIncremental();

    console.log(`âœ… Re-inferred: ${path}`);
  }
}

// ì‚¬ìš©
const watcher = new InferenceWatcher(engine, analyzer, db);
await watcher.start({
  patterns: ['src/**/*.ts'],
  ignored: ['node_modules/**', 'dist/**']
});
```

**Acceptance Criteria**:
- íŒŒì¼ ë³€ê²½ ê°ì§€
- Debouncing ë™ì‘
- ì¦ë¶„ ì¶”ë¡  ìë™ ì‹¤í–‰

---

## Phase 5: Testing & Validation

### Task 5.1: Inference ì •í™•ë„ í…ŒìŠ¤íŠ¸
**Status**: â³ Pending
**Files**: `tests/inference-accuracy.test.ts`

**Tasks**:
- [ ] Ground truth dataset ì¤€ë¹„
- [ ] ì¶”ë¡  ê²°ê³¼ ë¹„êµ
- [ ] Precision/Recall ê³„ì‚°

**Test Dataset**:
```typescript
// fixtures/inference-ground-truth.json
{
  "hierarchical": [
    {
      "query": { "type": "imports", "includeChildren": true },
      "expected": [
        "imports_file",
        "imports_package",
        "imports_default"
      ]
    }
  ],
  "transitive": [
    {
      "query": { "nodeId": 1, "type": "depends_on", "maxDepth": 3 },
      "expected": [
        { "path": [1, 2], "depth": 1 },
        { "path": [1, 2, 3], "depth": 2 },
        { "path": [1, 2, 3, 4], "depth": 3 }
      ]
    }
  ]
}
```

**Acceptance Criteria**:
- Precision > 95%
- Recall > 90%
- F1-score > 92%

---

### Task 5.2: ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬
**Status**: â³ Pending
**Files**: `tests/inference-benchmark.test.ts`

**Tasks**:
- [ ] ë‹¤ì–‘í•œ í¬ê¸°ì˜ í”„ë¡œì íŠ¸ ì¤€ë¹„ (Small/Medium/Large)
- [ ] ì¶”ë¡  ì‹œê°„ ì¸¡ì •
- [ ] Memory usage ì¸¡ì •

**Benchmark Scenarios**:
```typescript
describe('Inference Performance', () => {
  it('should handle small project (< 100 nodes)', async () => {
    const start = performance.now();
    await engine.inferAll();
    const duration = performance.now() - start;

    expect(duration).toBeLessThan(100);  // < 100ms
  });

  it('should handle medium project (100-500 nodes)', async () => {
    const start = performance.now();
    await engine.inferAll();
    const duration = performance.now() - start;

    expect(duration).toBeLessThan(500);  // < 500ms
  });

  it('should handle large project (500+ nodes)', async () => {
    const start = performance.now();
    await engine.inferAll();
    const duration = performance.now() - start;

    expect(duration).toBeLessThan(2000);  // < 2s
  });
});
```

**Acceptance Criteria**:
- Small project < 100ms
- Medium project < 500ms
- Large project < 2s

---

## Summary

### Progress Tracker
```
Phase 1: Core Inference Implementation  [â–±â–±â–±] 0/3 tasks
Phase 2: Advanced Query Language        [â–±] 0/1 task
Phase 3: Custom Inference Rules         [â–±â–±] 0/2 tasks
Phase 4: Real-Time Inference            [â–±] 0/1 task
Phase 5: Testing & Validation           [â–±â–±] 0/2 tasks

Total: 0/9 tasks completed (0%)
```

### Estimated Timeline
- Phase 1: 6-8 days
- Phase 2: 4-5 days
- Phase 3: 3-4 days
- Phase 4: 2-3 days
- Phase 5: 3-4 days

**Total**: ~18-24 days

### Dependencies
- Phase 2-4 require Phase 1 completion
- Phase 5 requires all other phases

### Priority Ranking
1. **High**: Task 1.1, 1.2 (Core optimization)
2. **Medium**: Task 1.3, 3.1, 3.2 (Symbol-level + Rules)
3. **Low**: Task 2.1, 4.1 (Advanced features)

---

**Last Updated**: 2025-10-05
**Next Review**: Task 1.1 completion
