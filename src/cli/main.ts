/**
 * Main CLI Entry Point
 * ÌÜµÌï© CLI ÏßÑÏûÖÏ†ê
 */

import { Command } from "commander";
import fs from "fs";
import path from "path";
import {
	AnalysisNamespaceManager,
	runNamespaceAnalysis,
} from "../namespace/analysis-namespace.js";
import {
	createRDFAddress,
	parseRDFAddress,
	validateRDFAddress,
} from "../core/RDFAddress.js";
import {
	searchRDFAddresses,
	filterRDFAddresses,
	groupRDFAddressesBy,
	generateRDFAddressStatistics,
} from "../core/RDFAddressParser.js";
import {
	createRDFNodeIdentifier,
	validateRDFNodeIdentifier,
} from "../core/RDFNodeIdentifier.js";
import {
	validateRDFUniqueness,
	suggestConflictResolution,
} from "../core/RDFUniquenessValidator.js";
import { RDFDatabaseAPI } from "../api/rdf-database-integration.js";

const program = new Command();

program
	.name("dependency-linker")
	.description(
		"Advanced TypeScript dependency analysis and compliance checking tool",
	)
	.version("2.1.0");

// ===== NAMESPACE COMMANDS =====

program
	.command("namespace")
	.description("Namespace-based analysis management")
	.option(
		"-c, --config <file>",
		"Configuration file path",
		"./dependency-linker.config.json",
	)
	.option("-n, --name <name>", "Specific namespace to run")
	.option("-a, --all", "Run all enabled namespaces")
	.option("--list", "List all namespaces")
	.option("--add <name>", "Add new namespace")
	.option("--remove <name>", "Remove namespace")
	.option("--queries", "Show available query categories")
	.option("--queries-for <namespace>", "Show queries for specific namespace")
	.action(async (options) => {
		try {
			const manager = new AnalysisNamespaceManager(options.config);

			if (options.queries) {
				// ÏøºÎ¶¨ Ïπ¥ÌÖåÍ≥†Î¶¨ Î™©Î°ù Ï∂úÎ†•
				const categories = manager.getQueryCategories();
				console.log("üîç Available Query Categories:");
				console.log("=".repeat(50));

				for (const [category, info] of Object.entries(categories)) {
					console.log(`üìä ${info.name} (${category})`);
					console.log(`   Description: ${info.description}`);
					console.log(`   Query Count: ${info.queryCount} queries`);
					console.log();
				}

				return;
			}

			if (options.queriesFor) {
				// ÌäπÏ†ï ÎÑ§ÏûÑÏä§ÌéòÏù¥Ïä§Ïùò ÏøºÎ¶¨ Î™©Î°ù Ï∂úÎ†•
				const config = await manager.loadConfig();
				const activeQueries = await manager.getActiveQueriesForNamespace(
					options.queriesFor,
				);
				const namespace = config.namespaces[options.queriesFor];

				if (!namespace) {
					console.log(`‚ùå Namespace '${options.queriesFor}' not found`);
					return;
				}

				console.log(`üîç Queries for namespace '${options.queriesFor}':`);
				console.log("=".repeat(50));
				console.log(
					`Categories: ${namespace.queries?.categories?.join(", ") || "none"}`,
				);
				console.log(
					`Custom queries: ${namespace.queries?.custom?.enabled ? "enabled" : "disabled"}`,
				);
				console.log(`Total queries: ${activeQueries.length}`);
				console.log();
				console.log("Active queries:");
				activeQueries.forEach((query, index) => {
					console.log(`  ${index + 1}. ${query}`);
				});

				return;
			}

			if (options.list) {
				// ÎÑ§ÏûÑÏä§ÌéòÏù¥Ïä§ Î™©Î°ù Ï∂úÎ†•
				const config = await manager.loadConfig();
				console.log("üìã Available Namespaces:");
				console.log("=".repeat(50));

				for (const [name, namespace] of Object.entries(config.namespaces)) {
					const status = namespace.analysis.enabled ? "‚úÖ" : "‚ùå";
					const schedule = namespace.schedule?.enabled ? "‚è∞" : "";
					const activeQueries =
						await manager.getActiveQueriesForNamespace(name);
					console.log(`${status} ${schedule} ${name}`);
					console.log(`   Description: ${namespace.description}`);
					console.log(`   Patterns: ${namespace.patterns.include.join(", ")}`);
					console.log(`   Queries: ${activeQueries.length} active queries`);
					console.log(`   Output: ${namespace.output.destination}`);
					console.log();
				}

				return;
			}

			if (options.add) {
				// ÏÉà ÎÑ§ÏûÑÏä§ÌéòÏù¥Ïä§ Ï∂îÍ∞Ä (ÎåÄÌôîÌòï)
				console.log(`‚ûï Adding new namespace: ${options.add}`);
				// Ïó¨Í∏∞ÏÑú ÎåÄÌôîÌòï ÎÑ§ÏûÑÏä§ÌéòÏù¥Ïä§ ÏÉùÏÑ± Î°úÏßÅ Ï∂îÍ∞Ä
				console.log("üí° Use --interactive flag for guided setup");
				return;
			}

			if (options.remove) {
				// ÎÑ§ÏûÑÏä§ÌéòÏù¥Ïä§ Ï†úÍ±∞
				await manager.removeNamespace(options.remove);
				console.log(`üóëÔ∏è  Removed namespace: ${options.remove}`);
				return;
			}

			if (options.name) {
				// ÌäπÏ†ï ÎÑ§ÏûÑÏä§ÌéòÏù¥Ïä§ Ïã§Ìñâ
				await manager.runNamespace(options.name);
			} else if (options.all) {
				// Î™®Îì† ÎÑ§ÏûÑÏä§ÌéòÏù¥Ïä§ Ïã§Ìñâ
				await manager.runAllNamespaces();
			} else {
				console.log(
					"‚ùå Please specify --name, --all, --list, --add, or --remove",
				);
				process.exit(1);
			}
		} catch (error) {
			console.error("‚ùå Namespace operation failed:", error);
			process.exit(1);
		}
	});

// ===== WATCH COMMAND =====

program
	.command("watch")
	.description("Watch files and run analysis automatically")
	.option(
		"-c, --config <file>",
		"Configuration file path",
		"./dependency-linker.config.json",
	)
	.option("-n, --namespace <name>", "Specific namespace to watch")
	.option("-i, --interval <ms>", "Check interval in milliseconds", "5000")
	.action(async (options) => {
		try {
			console.log("üëÄ Starting file watcher...\n");

			const manager = new AnalysisNamespaceManager(options.config);
			const interval = parseInt(options.interval);

			let lastAnalysis = new Date(0);
			const fileTimestamps = new Map<string, Date>();

			const checkFiles = async () => {
				try {
					const config = await manager.loadConfig();
					const namespaces = options.namespace
						? [config.namespaces[options.namespace]].filter(Boolean)
						: Object.values(config.namespaces);

					let hasChanges = false;

					for (const namespace of namespaces) {
						if (!namespace.analysis.enabled) continue;

						// ÎÑ§ÏûÑÏä§ÌéòÏù¥Ïä§Ïùò ÌååÏùºÎì§ ÌôïÏù∏
						const files = await manager["getFilesForNamespace"](namespace);

						for (const file of files) {
							if (!fs.existsSync(file)) continue;

							const stats = fs.statSync(file);
							const lastModified = stats.mtime;

							if (
								!fileTimestamps.has(file) ||
								fileTimestamps.get(file)! < lastModified
							) {
								fileTimestamps.set(file, lastModified);
								hasChanges = true;
							}
						}
					}

					if (hasChanges) {
						console.log(`üîÑ Files changed, running analysis...`);

						if (options.namespace) {
							await manager.runNamespace(options.namespace);
						} else {
							await manager.runAllNamespaces();
						}

						lastAnalysis = new Date();
					}
				} catch (error) {
					console.error("‚ùå Watch check failed:", error);
				}
			};

			// Ï¥àÍ∏∞ Ïã§Ìñâ
			await checkFiles();

			// Ï£ºÍ∏∞Ï†Å ÌôïÏù∏
			setInterval(checkFiles, interval);

			console.log(`üëÄ Watching files (interval: ${interval}ms)`);
			if (options.namespace) {
				console.log(`üìÅ Namespace: ${options.namespace}`);
			} else {
				console.log(`üìÅ All enabled namespaces`);
			}
		} catch (error) {
			console.error("‚ùå Watch failed:", error);
			process.exit(1);
		}
	});

// ===== SCHEDULE COMMAND =====

program
	.command("schedule")
	.description("Run scheduled analysis")
	.option(
		"-c, --config <file>",
		"Configuration file path",
		"./dependency-linker.config.json",
	)
	.option("--daemon", "Run as daemon process")
	.action(async (options) => {
		try {
			const manager = new AnalysisNamespaceManager(options.config);

			if (options.daemon) {
				console.log("üîÑ Starting daemon process...");

				// 1Î∂ÑÎßàÎã§ Ïä§ÏºÄÏ§Ñ ÌôïÏù∏
				setInterval(async () => {
					try {
						await manager.runScheduledAnalysis();
					} catch (error) {
						console.error("‚ùå Scheduled analysis failed:", error);
					}
				}, 60000);

				console.log("‚úÖ Daemon started. Press Ctrl+C to stop.");

				// ÌîÑÎ°úÏÑ∏Ïä§ Ï¢ÖÎ£å Ïã†Ìò∏ Ï≤òÎ¶¨
				process.on("SIGINT", () => {
					console.log("\nüëã Daemon stopped.");
					process.exit(0);
				});

				// ÌîÑÎ°úÏÑ∏Ïä§ Ïú†ÏßÄ
				await new Promise(() => {});
			} else {
				// ÏùºÌöåÏÑ± Ïä§ÏºÄÏ§Ñ Ïã§Ìñâ
				await manager.runScheduledAnalysis();
				console.log("‚úÖ Scheduled analysis completed");
			}
		} catch (error) {
			console.error("‚ùå Schedule operation failed:", error);
			process.exit(1);
		}
	});

// ===== INIT COMMAND =====

program
	.command("init")
	.description("Initialize dependency-linker configuration")
	.option("-p, --project <name>", "Project name", "my-project")
	.option("-d, --directory <dir>", "Project directory", ".")
	.option(
		"-c, --config <file>",
		"Configuration file path",
		"./dependency-linker.config.json",
	)
	.action(async (options) => {
		try {
			console.log("üöÄ Initializing dependency-linker...\n");

			const manager = new AnalysisNamespaceManager(options.config);
			const config = await manager.loadConfig();

			// ÌîÑÎ°úÏ†ùÌä∏ Ï†ïÎ≥¥ ÏóÖÎç∞Ïù¥Ìä∏
			config.projectName = options.project;
			config.rootPath = path.resolve(options.directory);

			await manager.saveConfig();

			console.log("‚úÖ Configuration initialized!");
			console.log(`üìÅ Project: ${config.projectName}`);
			console.log(`üìÇ Root: ${config.rootPath}`);
			console.log(`üìÑ Config: ${options.config}`);
			console.log("\nüí° Next steps:");
			console.log(
				"  1. Review and customize namespaces: dependency-linker namespace --list",
			);
			console.log("  2. Run analysis: dependency-linker namespace --all");
			console.log("  3. Set up watching: dependency-linker watch");
		} catch (error) {
			console.error("‚ùå Initialization failed:", error);
			process.exit(1);
		}
	});

// ===== ANALYSIS COMMANDS (from analysis-cli) =====

program
	.command("analyze")
	.description("Direct file analysis (bypass namespace)")
	.option("-p, --pattern <pattern>", "File pattern to analyze", "**/*.ts")
	.option("-d, --directory <dir>", "Directory to analyze", ".")
	.option("-o, --output <file>", "Output file path")
	.option("-f, --format <format>", "Output format", "json")
	.option("--include-metadata", "Include metadata in output", false)
	.option("--include-statistics", "Include statistics in output", true)
	.option("--compliance", "Run compliance checks", false)
	.option("--performance", "Enable performance optimizations", false)
	.option("--max-concurrency <number>", "Maximum concurrent files", "8")
	.option("--batch-size <number>", "Batch size for processing", "50")
	.option("--memory-limit <mb>", "Memory limit in MB", "1024")
	.action(async (options) => {
		try {
			console.log("üîç Running direct analysis...\n");

			// ÌååÏùº Ìå®ÌÑ¥ÏúºÎ°ú ÌååÏùº Ï∞æÍ∏∞
			const { glob } = await import("glob");
			const files = await glob(options.pattern, { cwd: options.directory });

			if (files.length === 0) {
				console.log("‚ùå No files found matching the pattern");
				return;
			}

			console.log(`üìÅ Found ${files.length} files to analyze`);

			let report: any;

			if (options.performance) {
				// ÏÑ±Îä• ÏµúÏ†ÅÌôîÎêú Î∂ÑÏÑù Ïã§Ìñâ
				console.log("‚ö° Using performance optimizations...");
				const { analyzeFilesWithPerformance, DEFAULT_PERFORMANCE_CONFIG } =
					await import("../api/performance-analysis.js");

				const config = {
					...DEFAULT_PERFORMANCE_CONFIG,
					maxConcurrency: parseInt(options.maxConcurrency),
					batchSize: parseInt(options.batchSize),
					memoryLimit: parseInt(options.memoryLimit),
				};

				const results = await analyzeFilesWithPerformance(
					files,
					"typescript",
					config,
				);

				// ÏÑ±Îä• ÏµúÏ†ÅÌôîÎêú Î¶¨Ìè¨Ìä∏ ÏÉùÏÑ±
				report = {
					timestamp: new Date(),
					summary: results.summary,
					symbols: results.results.flatMap((r: any) => r.symbols || []),
					errors: results.results.flatMap((r: any) => r.errors || []),
					statistics: {
						byType: {},
						byFile: {},
						byExport: { exported: 0, internal: 0 },
					},
					performance: results.metrics,
					cacheStats: results.cacheStats,
				};

				// ÌÜµÍ≥Ñ Í≥ÑÏÇ∞
				for (const result of results.results) {
					if (result.symbols) {
						for (const symbol of result.symbols) {
							report.statistics.byType[symbol.type] =
								(report.statistics.byType[symbol.type] || 0) + 1;
							report.statistics.byFile[result.filePath] =
								(report.statistics.byFile[result.filePath] || 0) + 1;
							if (symbol.isExported) {
								report.statistics.byExport.exported++;
							} else {
								report.statistics.byExport.internal++;
							}
						}
					}
				}
			} else {
				// Í∏∞Î≥∏ Í∞ïÍ±¥Ìïú Î∂ÑÏÑù Ïã§Ìñâ
				const { analyzeFilesRobust, generateRobustAnalysisReport } =
					await import("../api/robust-analysis.js");
				const results = await analyzeFilesRobust(files, "typescript");
				report = generateRobustAnalysisReport(results.results);
			}

			// Ï∂úÎ†•
			if (options.output) {
				const fs = await import("fs");
				const path = await import("path");

				const outputPath = path.resolve(options.output);
				const outputDir = path.dirname(outputPath);

				if (!fs.existsSync(outputDir)) {
					fs.mkdirSync(outputDir, { recursive: true });
				}

				let content: string;
				switch (options.format) {
					case "json":
						content = JSON.stringify(report, null, 2);
						break;
					case "csv":
						content = generateCSV(report);
						break;
					default:
						content = JSON.stringify(report, null, 2);
				}

				fs.writeFileSync(outputPath, content);
				console.log(`üìÑ Report saved to ${outputPath}`);
			} else {
				// ÏΩòÏÜî Ï∂úÎ†•
				console.log("\nüìä Analysis Report:");
				console.log("=".repeat(50));
				console.log(`üìÅ Files analyzed: ${report.summary.totalFiles}`);
				console.log(`üîç Total symbols: ${report.summary.totalSymbols}`);
				console.log(`‚ùå Total errors: ${report.summary.totalErrors}`);
				console.log(
					`üìä Success rate: ${report.summary.successRate.toFixed(1)}%`,
				);

				if (report.summary.parseMethodStats) {
					console.log(
						`üå≥ Tree-sitter: ${report.summary.parseMethodStats.treeSitter}`,
					);
					console.log(
						`üîß Regex fallback: ${report.summary.parseMethodStats.regexFallback}`,
					);
				}

				if (report.performance) {
					console.log(`‚ö° Performance metrics:`);
					console.log(`   Time: ${report.performance.totalTime.toFixed(2)}ms`);
					console.log(
						`   Files/sec: ${report.performance.filesPerSecond.toFixed(2)}`,
					);
					console.log(
						`   Symbols/sec: ${report.performance.symbolsPerSecond.toFixed(2)}`,
					);
					console.log(
						`   Memory: ${(report.performance.peakMemoryUsage / 1024 / 1024).toFixed(2)}MB peak`,
					);
				}

				if (report.cacheStats) {
					console.log(
						`üíæ Cache: ${report.cacheStats.hits} hits, ${report.cacheStats.misses} misses`,
					);
				}

				if (options.includeStatistics) {
					console.log("\nüìà Statistics:");
					console.log("By type:", report.statistics.byType);
					console.log(
						"By file:",
						Object.keys(report.statistics.byFile).slice(0, 5),
						"...",
					);
				}
			}

			console.log("\n‚úÖ Analysis completed successfully!");
		} catch (error) {
			console.error("‚ùå Analysis failed:", error);
			process.exit(1);
		}
	});

program
	.command("compliance")
	.description("Check code compliance")
	.option("-p, --pattern <pattern>", "File pattern to analyze", "**/*.ts")
	.option("-d, --directory <dir>", "Directory to analyze", ".")
	.option("-r, --rules <file>", "Custom compliance rules file")
	.option("--severity <level>", "Minimum severity level", "info")
	.action(async (options) => {
		// analysis-cliÏùò compliance Î™ÖÎ†πÏñ¥ Î°úÏßÅÏùÑ Ïó¨Í∏∞Ïóê ÌÜµÌï©
		console.log("üìã Running compliance checks...");
		// Íµ¨ÌòÑ ÏÉùÎûµ - analysis-cli.tsÏùò Î°úÏßÅ Ïû¨ÏÇ¨Ïö©
	});

// ===== HELP AND VERSION =====

program
	.command("help")
	.description("Show detailed help information")
	.action(() => {
		console.log(`
üîç Dependency Linker - Advanced TypeScript Analysis Tool

üìã Available Commands:
  namespace    Manage and run namespace-based analysis
  watch        Watch files for changes and run analysis
  schedule     Run scheduled analysis (daemon mode)
  analyze      Direct file analysis (bypass namespace)
  compliance   Check code compliance against rules
  init         Initialize configuration
  help         Show this help

üìö Examples:
  # Initialize project
  dependency-linker init --project my-app

  # List namespaces
  dependency-linker namespace --list

  # Run specific namespace
  dependency-linker namespace --name source

  # Run all namespaces
  dependency-linker namespace --all

  # Watch for changes
  dependency-linker watch --namespace source

  # Run compliance checks
  dependency-linker compliance --severity warning

  # Direct analysis
  dependency-linker analyze --pattern "src/**/*.ts" --compliance

üìñ For more information, visit: https://github.com/your-repo/dependency-linker
    `);
	});

// ===== HELPER FUNCTIONS =====

function generateCSV(report: any): string {
	const headers = [
		"name",
		"type",
		"filePath",
		"startLine",
		"endLine",
		"isExported",
	];
	const rows = report.symbols.map((symbol: any) => [
		symbol.name,
		symbol.type,
		symbol.filePath,
		symbol.startLine.toString(),
		symbol.endLine.toString(),
		symbol.isExported.toString(),
	]);

	return [headers.join(","), ...rows.map((row: any) => row.join(","))].join(
		"\n",
	);
}

// ===== RDF COMMANDS =====

program
	.command("rdf")
	.description("RDF address management and analysis")
	.option("--create", "Create RDF address")
	.option("--search", "Search RDF addresses")
	.option("--validate", "Validate RDF addresses")
	.option("--stats", "Show RDF address statistics")
	.option("--project <name>", "Project name for RDF address")
	.option("--file <path>", "File path for RDF address")
	.option("--type <type>", "Node type for RDF address")
	.option("--symbol <name>", "Symbol name for RDF address")
	.option("--query <query>", "Search query")
	.option("--namespace <name>", "Namespace to analyze")
	.option("--format <format>", "Output format (json, csv, table)", "table")
	.option("--uniqueness", "Check uniqueness validation")
	.option("--conflicts", "Show conflict resolution suggestions")
	.option("--db", "Use database integration")
	.option("--db-path <path>", "Database file path", "./dependency-linker.db")
	.option("--store", "Store RDF addresses to database")
	.option("--load", "Load RDF addresses from database")
	.option("--relationships", "Show RDF relationships")
	.option("--store-relationship", "Store RDF relationship")
	.option("--source <address>", "Source RDF address for relationship")
	.option("--target <address>", "Target RDF address for relationship")
	.option("--rel-type <type>", "Relationship type")
	.action(async (options) => {
		try {
			if (options.create) {
				await handleRDFCreate(options);
			} else if (options.search) {
				await handleRDFSearch(options);
			} else if (options.validate) {
				await handleRDFValidate(options);
			} else if (options.stats) {
				await handleRDFStats(options);
			} else if (options.store) {
				await handleRDFStore(options);
			} else if (options.load) {
				await handleRDFLoad(options);
			} else if (options.relationships) {
				await handleRDFRelationships(options);
			} else if (options.storeRelationship) {
				await handleRDFStoreRelationship(options);
			} else {
				console.log(
					"‚ùå Please specify an RDF command: --create, --search, --validate, --stats, --store, --load, --relationships, or --store-relationship",
				);
				process.exit(1);
			}
		} catch (error) {
			console.error("‚ùå RDF command failed:", error);
			process.exit(1);
		}
	});

// ===== RDF COMMAND HANDLERS =====

async function handleRDFCreate(options: any) {
	const { project, file, type, symbol } = options;

	if (!project || !file || !type || !symbol) {
		console.log("‚ùå Missing required options for RDF create:");
		console.log("   --project <name> - Project name");
		console.log("   --file <path> - File path");
		console.log("   --type <type> - Node type (Class, Method, Function, etc.)");
		console.log("   --symbol <name> - Symbol name");
		process.exit(1);
	}

	try {
		const rdfAddress = createRDFAddress({
			projectName: project,
			filePath: file,
			nodeType: type as any,
			symbolName: symbol,
			validate: true,
		});

		console.log("‚úÖ RDF Address Created:");
		console.log(`   ${rdfAddress}`);

		// Validate the created address
		const validation = validateRDFAddress(rdfAddress);
		if (validation.isValid) {
			console.log("‚úÖ Address is valid");
		} else {
			console.log("‚ùå Address validation failed:");
			validation.errors?.forEach((error) => console.log(`   - ${error}`));
		}
	} catch (error: any) {
		console.error("‚ùå Failed to create RDF address:", error);
		process.exit(1);
	}
}

async function handleRDFSearch(options: any) {
	const { query, namespace, format } = options;

	if (!query) {
		console.log("‚ùå Missing required option: --query <query>");
		process.exit(1);
	}

	try {
		// TODO: Load existing RDF addresses from database or files
		// For now, we'll create some sample addresses for demonstration
		const sampleAddresses = [
			"dependency-linker/src/parser.ts#Class:TypeScriptParser",
			"dependency-linker/src/parser.ts#Method:TypeScriptParser.parse",
			"dependency-linker/src/graph.ts#Class:DependencyGraph",
			"dependency-linker/src/graph.ts#Method:DependencyGraph.addNode",
			"dependency-linker/src/cli.ts#Function:main",
		];

		const results = searchRDFAddresses(query, sampleAddresses, {
			caseSensitive: false,
			exactMatch: false,
			includeProject: true,
		});

		console.log(`üîç Search Results for "${query}":`);
		console.log("=".repeat(50));

		if (results.length === 0) {
			console.log("No results found");
			return;
		}

		if (format === "json") {
			console.log(JSON.stringify(results, null, 2));
		} else if (format === "csv") {
			const csv = results
				.map(
					(r) =>
						`${r.rdfAddress},${r.filePath},${r.projectName},${r.symbolName},${r.nodeType},${r.confidence}`,
				)
				.join("\n");
			console.log(
				"rdfAddress,filePath,projectName,symbolName,nodeType,confidence",
			);
			console.log(csv);
		} else {
			results.forEach((result, index) => {
				console.log(`${index + 1}. ${result.symbolName} (${result.nodeType})`);
				console.log(`   Address: ${result.rdfAddress}`);
				console.log(`   File: ${result.filePath}`);
				console.log(`   Confidence: ${(result.confidence * 100).toFixed(1)}%`);
				console.log();
			});
		}
	} catch (error: any) {
		console.error("‚ùå Search failed:", error);
		process.exit(1);
	}
}

async function handleRDFValidate(options: any) {
	const { namespace, uniqueness, conflicts } = options;

	try {
		// TODO: Load RDF addresses from namespace or database
		// For now, we'll validate a sample address
		const sampleAddress =
			"dependency-linker/src/parser.ts#Method:TypeScriptParser.parse";

		console.log("üîç RDF Address Validation:");
		console.log("=".repeat(50));

		// Basic validation
		const validation = validateRDFAddress(sampleAddress);
		console.log(`Address: ${sampleAddress}`);
		console.log(`Valid: ${validation.isValid ? "‚úÖ Yes" : "‚ùå No"}`);

		if (validation.errors) {
			console.log("Errors:");
			validation.errors.forEach((error) => console.log(`  - ${error}`));
		}

		// Parse and display details
		const parsed = parseRDFAddress(sampleAddress);
		if (parsed.isValid) {
			console.log("\nüìã Parsed Details:");
			console.log(`  Project: ${parsed.projectName}`);
			console.log(`  File: ${parsed.filePath}`);
			console.log(`  Type: ${parsed.nodeType}`);
			console.log(`  Symbol: ${parsed.symbolName}`);
		}

		if (uniqueness) {
			console.log("\nüîç Uniqueness Validation:");
			// TODO: Implement uniqueness validation with actual data
			console.log("  (Uniqueness validation requires database integration)");
		}

		if (conflicts) {
			console.log("\nüí° Conflict Resolution Suggestions:");
			// TODO: Implement conflict resolution suggestions
			console.log("  (Conflict resolution requires database integration)");
		}
	} catch (error: any) {
		console.error("‚ùå Validation failed:", error);
		process.exit(1);
	}
}

async function handleRDFStats(options: any) {
	const { namespace, format } = options;

	try {
		// TODO: Load RDF addresses from namespace or database
		// For now, we'll create sample statistics
		const sampleAddresses = [
			"dependency-linker/src/parser.ts#Class:TypeScriptParser",
			"dependency-linker/src/parser.ts#Method:TypeScriptParser.parse",
			"dependency-linker/src/parser.ts#Method:TypeScriptParser.validate",
			"dependency-linker/src/graph.ts#Class:DependencyGraph",
			"dependency-linker/src/graph.ts#Method:DependencyGraph.addNode",
			"dependency-linker/src/graph.ts#Method:DependencyGraph.addEdge",
			"dependency-linker/src/cli.ts#Function:main",
			"dependency-linker/src/cli.ts#Function:handleError",
		];

		const stats = generateRDFAddressStatistics(sampleAddresses);

		console.log("üìä RDF Address Statistics:");
		console.log("=".repeat(50));

		if (format === "json") {
			console.log(JSON.stringify(stats, null, 2));
		} else {
			console.log(`Total Addresses: ${stats.totalAddresses}`);
			console.log(`Projects: ${stats.projectCount}`);
			console.log(`Files: ${stats.fileCount}`);
			console.log(`Invalid Addresses: ${stats.invalidAddresses}`);

			console.log("\nüìà By Node Type:");
			Object.entries(stats.nodeTypeCount).forEach(([type, count]) => {
				console.log(`  ${type}: ${count}`);
			});

			console.log("\nüìÅ By Namespace:");
			Object.entries(stats.namespaceCount).forEach(([ns, count]) => {
				console.log(`  ${ns}: ${count}`);
			});
		}
	} catch (error: any) {
		console.error("‚ùå Statistics failed:", error);
		process.exit(1);
	}
}

async function handleRDFStore(options: any) {
	const { project, file, type, symbol, dbPath } = options;

	if (!project || !file || !type || !symbol) {
		console.log("‚ùå Missing required options for RDF store:");
		console.log("   --project <name> - Project name");
		console.log("   --file <path> - File path");
		console.log("   --type <type> - Node type (Class, Method, Function, etc.)");
		console.log("   --symbol <name> - Symbol name");
		process.exit(1);
	}

	try {
		const api = new RDFDatabaseAPI(dbPath);
		await api.initialize();

		// RDF Ï£ºÏÜå ÏÉùÏÑ±
		const rdfAddress = createRDFAddress({
			projectName: project,
			filePath: file,
			nodeType: type as any,
			symbolName: symbol,
			validate: true,
		});

		// Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§Ïóê Ï†ÄÏû•
		await api.storeRDFAddress({
			rdfAddress,
			projectName: project,
			filePath: file,
			nodeType: type as any,
			symbolName: symbol,
		});

		console.log("‚úÖ RDF Address Stored to Database:");
		console.log(`   ${rdfAddress}`);
		console.log(`   Database: ${dbPath}`);

		await api.close();
	} catch (error: any) {
		console.error("‚ùå Failed to store RDF address:", error);
		process.exit(1);
	}
}

async function handleRDFLoad(options: any) {
	const { query, project, file, type, namespace, dbPath, format } = options;

	try {
		const api = new RDFDatabaseAPI(dbPath);
		await api.initialize();

		// Í≤ÄÏÉâ ÏòµÏÖò Íµ¨ÏÑ±
		const searchOptions: any = {};
		if (project) searchOptions.projectName = project;
		if (file) searchOptions.filePath = file;
		if (type) searchOptions.nodeType = type;
		if (namespace) searchOptions.namespace = namespace;

		// RDF Ï£ºÏÜå Í≤ÄÏÉâ
		const results = await api.searchRDFAddresses(query || "", searchOptions);

		console.log(`üîç RDF Addresses from Database:`);
		console.log("=".repeat(50));

		if (results.length === 0) {
			console.log("No RDF addresses found in database");
			return;
		}

		if (format === "json") {
			console.log(JSON.stringify(results, null, 2));
		} else if (format === "csv") {
			const csv = results
				.map(
					(r) =>
						`${r.rdfAddress},${r.projectName},${r.filePath},${r.nodeType},${r.symbolName},${r.namespace || ""},${r.lineNumber || ""},${r.columnNumber || ""}`,
				)
				.join("\n");
			console.log(
				"rdfAddress,projectName,filePath,nodeType,symbolName,namespace,lineNumber,columnNumber",
			);
			console.log(csv);
		} else {
			results.forEach((result, index) => {
				console.log(`${index + 1}. ${result.symbolName} (${result.nodeType})`);
				console.log(`   Address: ${result.rdfAddress}`);
				console.log(`   Project: ${result.projectName}`);
				console.log(`   File: ${result.filePath}`);
				if (result.namespace) console.log(`   Namespace: ${result.namespace}`);
				if (result.lineNumber)
					console.log(`   Line: ${result.lineNumber}:${result.columnNumber}`);
				console.log();
			});
		}

		await api.close();
	} catch (error: any) {
		console.error("‚ùå Failed to load RDF addresses:", error);
		process.exit(1);
	}
}

async function handleRDFRelationships(options: any) {
	const { query, dbPath, format } = options;

	if (!query) {
		console.log("‚ùå Missing required option: --query <rdf-address>");
		process.exit(1);
	}

	try {
		const api = new RDFDatabaseAPI(dbPath);
		await api.initialize();

		// RDF Í¥ÄÍ≥Ñ Í≤ÄÏÉâ
		const relationships = await api.getRDFRelationships(query);

		console.log(`üîó RDF Relationships for "${query}":`);
		console.log("=".repeat(50));

		if (relationships.length === 0) {
			console.log("No relationships found");
			return;
		}

		if (format === "json") {
			console.log(JSON.stringify(relationships, null, 2));
		} else if (format === "csv") {
			const csv = relationships
				.map(
					(r) =>
						`${r.sourceRdfAddress},${r.targetRdfAddress},${r.relationshipType},${JSON.stringify(r.metadata)}`,
				)
				.join("\n");
			console.log(
				"sourceRdfAddress,targetRdfAddress,relationshipType,metadata",
			);
			console.log(csv);
		} else {
			relationships.forEach((rel, index) => {
				console.log(`${index + 1}. ${rel.relationshipType}`);
				console.log(`   From: ${rel.sourceRdfAddress}`);
				console.log(`   To: ${rel.targetRdfAddress}`);
				if (Object.keys(rel.metadata).length > 0) {
					console.log(`   Metadata: ${JSON.stringify(rel.metadata)}`);
				}
				console.log();
			});
		}

		await api.close();
	} catch (error: any) {
		console.error("‚ùå Failed to load RDF relationships:", error);
		process.exit(1);
	}
}

async function handleRDFStoreRelationship(options: any) {
	const { source, target, relType, dbPath } = options;

	if (!source || !target || !relType) {
		console.log("‚ùå Missing required options for RDF relationship store:");
		console.log("   --source <address> - Source RDF address");
		console.log("   --target <address> - Target RDF address");
		console.log("   --rel-type <type> - Relationship type");
		process.exit(1);
	}

	try {
		const api = new RDFDatabaseAPI(dbPath);
		await api.initialize();

		// RDF Í¥ÄÍ≥Ñ Ï†ÄÏû•
		await api.storeRDFRelationship({
			sourceRdfAddress: source,
			targetRdfAddress: target,
			relationshipType: relType,
			metadata: {},
		});

		console.log("‚úÖ RDF Relationship Stored to Database:");
		console.log(`   From: ${source}`);
		console.log(`   To: ${target}`);
		console.log(`   Type: ${relType}`);
		console.log(`   Database: ${dbPath}`);

		await api.close();
	} catch (error: any) {
		console.error("‚ùå Failed to store RDF relationship:", error);
		process.exit(1);
	}
}

// ===== CLI EXECUTION =====

program.parse();

export { program };
